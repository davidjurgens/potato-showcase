{
  "title": "HelpSteer Multi-Attribute Rating",
  "description": "Multi-dimensional response quality rating for reward model training. Annotators rate AI responses on 5 attributes: helpfulness, correctness, coherence, complexity, and verbosity using a 0-4 scale.",
  "version": "1.0.0",
  "author": {
    "name": "Potato Team",
    "email": "jurgens@umich.edu",
    "github": "davidjurgens",
    "affiliation": "University of Michigan"
  },
  "createdAt": "2025-02-02",
  "updatedAt": "2025-02-02",
  "annotationTypes": ["likert", "multirate"],
  "domain": ["NLP", "AI Alignment"],
  "useCase": ["Reward Modeling", "RLHF", "Response Quality"],
  "complexity": "intermediate",
  "tags": ["preference", "rlhf", "helpsteer", "multi-attribute", "rating", "reward-model"],
  "featured": false,
  "paperReference": "Wang et al., NAACL 2024",
  "paperUrl": "https://aclanthology.org/2024.naacl-long.185.pdf",
  "datasetUrl": "https://huggingface.co/datasets/nvidia/HelpSteer2",
  "citation": "@inproceedings{wang2024helpsteer,\n  title={HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM},\n  author={Wang, Zhilin and Dong, Yi and Zeng, Jiaqi and Adams, Virginia and Sreedhar, Makesh Narsimhan and Egber, Daniel and Delalleau, Olivier and Scowcroft, Jane Polak and Kant, Neel and Swope, Aidan and Kuchaiev, Oleksii},\n  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics},\n  year={2024}\n}"
}
