{
  "title": "Charades Indoor Activity Segmentation",
  "description": "Multi-label temporal activity segmentation in indoor home videos. Annotators identify action instances using compositional verb-object labels (e.g., 'opening door', 'sitting on chair') with precise temporal boundaries.",
  "version": "1.0.0",
  "author": {
    "name": "Potato Team",
    "email": "jurgens@umich.edu",
    "github": "davidjurgens",
    "affiliation": "University of Michigan"
  },
  "createdAt": "2025-02-02",
  "updatedAt": "2025-02-02",
  "annotationTypes": ["video_annotation"],
  "domain": ["Computer Vision", "Video Understanding"],
  "useCase": ["Activity Recognition", "Action Segmentation", "Indoor Scene Understanding"],
  "complexity": "intermediate",
  "tags": ["video", "activity", "indoor", "charades", "compositional", "home"],
  "featured": false,
  "paperReference": "Sigurdsson et al., ECCV 2016",
  "paperUrl": "https://arxiv.org/pdf/1604.01753.pdf",
  "datasetUrl": "https://prior.allenai.org/projects/charades",
  "citation": "@inproceedings{sigurdsson2016hollywood,\n  title={Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding},\n  author={Sigurdsson, Gunnar A and Varol, G{\\\"u}l and Wang, Xiaolong and Farhadi, Ali and Laptev, Ivan and Gupta, Abhinav},\n  booktitle={European Conference on Computer Vision},\n  pages={510--526},\n  year={2016},\n  organization={Springer}\n}"
}
